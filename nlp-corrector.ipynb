{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport pandas as pd\nimport numpy as np\n\nimport re\nimport random\n\n\n\nimport time\nimport math\n\nfrom tqdm import tqdm\nfrom transformers import BertTokenizer,DistilBertTokenizer\nfrom transformers import  DistilBertModel,DistilBertConfig\n\n\nimport random\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T13:28:16.667459Z","iopub.execute_input":"2022-08-07T13:28:16.668013Z","iopub.status.idle":"2022-08-07T13:28:20.281258Z","shell.execute_reply.started":"2022-08-07T13:28:16.667923Z","shell.execute_reply":"2022-08-07T13:28:20.280005Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2022-08-07T14:55:12.221561Z","iopub.execute_input":"2022-08-07T14:55:12.222096Z","iopub.status.idle":"2022-08-07T14:55:12.229970Z","shell.execute_reply.started":"2022-08-07T14:55:12.222052Z","shell.execute_reply":"2022-08-07T14:55:12.228992Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained(\"dbmdz/distilbert-base-turkish-cased\")\nlanguage_model = DistilBertModel.from_pretrained(\"dbmdz/distilbert-base-turkish-cased\").to(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T13:28:20.283762Z","iopub.execute_input":"2022-08-07T13:28:20.284707Z","iopub.status.idle":"2022-08-07T13:28:40.778045Z","shell.execute_reply.started":"2022-08-07T13:28:20.284639Z","shell.execute_reply":"2022-08-07T13:28:40.777081Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with open('../input/tr-corpus-sent-txt/datasentbysent.txt') as f:\n    lines = f.readlines()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T14:55:26.240674Z","iopub.execute_input":"2022-08-07T14:55:26.241700Z","iopub.status.idle":"2022-08-07T14:55:32.079749Z","shell.execute_reply.started":"2022-08-07T14:55:26.241636Z","shell.execute_reply":"2022-08-07T14:55:32.078736Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Dataset(): #maxlen ekle padding de yap\n    def __init__(self,sentence,tokenizer,max_seq_len,device):\n        self.sentence = sentence \n        self.tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n        self.device = device\n    def __getitem__(self, index: int):\n        sent = self.sentence[index]\n        return (self.tokenizer(''.join(corrupt_sentence(sent)),max_length=self.max_seq_len,\n                          padding='max_length',\n                          return_tensors=\"pt\").to(self.device),\n            self.tokenizer(sent,max_length=self.max_seq_len,\n                          padding='max_length',\n                          return_tensors=\"pt\").to(self.device)\n)\n    def __len__(self) -> int:\n        return len(self.sentence)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T14:55:32.081781Z","iopub.execute_input":"2022-08-07T14:55:32.082135Z","iopub.status.idle":"2022-08-07T14:55:32.090073Z","shell.execute_reply.started":"2022-08-07T14:55:32.082098Z","shell.execute_reply":"2022-08-07T14:55:32.088987Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"pattern = '[?.\\n\\t&!]'\n#lines_ = [re.split(pattern,i) for i in lines]\nnoktali_sesli = {\"ı\":\"i\",\"ö\":\"o\",\"ü\":\"u\",\"ğ\":\"g\",\"ç\":\"c\",\"ş\":\"s\"}\nvowel = [\"a\",\"e\",\"ı\",\"i\",\"o\",\"ö\",\"u\",\"ü\",\"A\",\"E\",\"I\",\"İ\",\"O\",\"Ö\",\"U\",\"Ü\"]\nvowel_str = \"aeıioöuü\"\n\n\ndef containsVowels(string):\n    string = string.lower()\n    for char in string:\n        if char in vowel_str:\n            return True\n    return False\n\n\n\ndef dot_transform(word):\n    for char, replacement in noktali_sesli.items():\n        word = re.sub(char, replacement, word)\n    return word\n\n\ndef random_drop(word):\n    idx = random.randint(0,len(word)-1)\n    word = word[:idx] + word[idx+1:]\n    return word\n\n\ndef duplicate_char(word,max_dup = 3):\n    idx = random.randint(0,len(word)-1)\n    random_c = random.randint(1,max_dup)\n    word = word[:idx] + word[idx]*random_c + word[idx+1:]\n    return word\n\ndef drop_vowel(word):\n    idx = []\n    if not(containsVowels(word)):\n        return word\n    \n    for j,i in enumerate(word):\n        if i in vowel:\n            idx.append(j)\n            \n    #print(word,idx)\n    drop_idx = idx[random.randint(0,len(idx)-1)]\n    word = word = word[:drop_idx] + word[drop_idx+1:]\n    return word\n\ndef drop_all_vowels(word):\n    idx = []\n    \n    if not(containsVowels(word)):\n        return word\n    for j,i in enumerate(word):\n        if i in vowel:\n            idx.append(j)\n    for j,drop_idx in enumerate(idx):\n        word = word[:drop_idx-j] + word[drop_idx+1-j:]\n    return word\nlist_of_corruptions = [dot_transform,random_drop,drop_vowel,duplicate_char,drop_all_vowels]\ndef corrupt_word(word, corruption_prob= 0.8):\n    if len(word) < 2:\n        return word\n    prob = random.randint(1,10)/10\n    corruptions = []\n    while prob < corruption_prob:\n        corruptions.append(list_of_corruptions[random.randint(0,len(list_of_corruptions))-1])\n        prob = prob*2\n    for i in corruptions:\n        word = i(word)\n    return word\n        \n  \ndef corrupt_sentence(sentence,corruption_prob_w= 0.8,corruption_prob_s = 0.5):\n    words = sentence.split(\" \")\n\n    corrupt_num = int(len(words)*corruption_prob_s)\n    \n    c_idx = random.sample(range(0,len(words)-1),corrupt_num)\n    \n    for i in c_idx:\n        try:\n            words[i] = corrupt_word(words[i])+' '\n        except:\n            pass\n    return words\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T14:55:32.091566Z","iopub.execute_input":"2022-08-07T14:55:32.092170Z","iopub.status.idle":"2022-08-07T14:55:32.461947Z","shell.execute_reply.started":"2022-08-07T14:55:32.092133Z","shell.execute_reply":"2022-08-07T14:55:32.460880Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    \n    def __init__(self,d_model,n_heads,\n                 device,tokenizer,\n                 vocab_size,\n                 num_encoder_layers = 2,\n                 num_decoder_layers = 2,\n                 max_seq_len = 50,\n                 \n                ):\n        \n        super().__init__()\n        \n        self.transformer = nn.Transformer(d_model=d_model,\n                                          nhead=n_heads,\n                                          device = device,\n                                          num_encoder_layers = num_encoder_layers,\n                                          num_decoder_layers = num_decoder_layers,\n                                          dim_feedforward = 1024,\n                                          #batch_first=\n                                         )\n        self.tokenizer = tokenizer\n        self.pos_embed = nn.Parameter(torch.randn(max_seq_len,d_model))\n        self.max_seq_len = max_seq_len\n        self.embedding = nn.Embedding(num_embeddings=vocab_size,embedding_dim=d_model,)\n        self.norm = nn.LayerNorm(d_model)\n        self.output = nn.Linear(d_model,vocab_size)\n        \n        \n    def forward(self,src_input_ids,src_att_mask,trg_input_ids,space_shift):\n        \n\n        \n        embeds_trg = (self.embedding(trg_input_ids) + self.pos_embed + space_shift).permute(1, 0, 2)\n        embeds_src = (self.embedding(src_input_ids) + self.pos_embed + space_shift).permute(1, 0, 2)\n        \n        \n        transformer_outs = self.transformer(embeds_src,embeds_trg) # b x N x d\n        # b x N x e\n        \n        out = self.norm(transformer_outs)\n        out = self.output(out)\n        return out\n    \n\n        \n    \n    \n    def num_of_parameters(self,):\n\n        return sum(p.numel() for p in self.parameters())\n\ndef encode(sentence,corrupt=False):\n\n    \n\n\n    return tokenizer(sentence,max_length=max_seq_len,\n                          padding='max_length',\n                          return_tensors=\"pt\").to(device)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T14:55:32.464644Z","iopub.execute_input":"2022-08-07T14:55:32.465056Z","iopub.status.idle":"2022-08-07T14:55:32.477452Z","shell.execute_reply.started":"2022-08-07T14:55:32.465011Z","shell.execute_reply":"2022-08-07T14:55:32.476549Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"### HYPERPARAMETERS\nmax_seq_len = 250\nLR = 0.0031\nn_iter = 10000\nbatch_size = 16\nshuffle = True\nupdate_bar_per_iter = 1\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:23:19.149951Z","iopub.execute_input":"2022-08-07T15:23:19.150520Z","iopub.status.idle":"2022-08-07T15:23:19.155418Z","shell.execute_reply.started":"2022-08-07T15:23:19.150483Z","shell.execute_reply":"2022-08-07T15:23:19.154369Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"\n\ntrans = Transformer(d_model = 768,n_heads = 4,\n                    device = device,vocab_size = tokenizer.vocab_size,\n                    tokenizer = tokenizer,\n                    max_seq_len = max_seq_len,\n                    ).to(device)\n\nloss_fn = nn.CrossEntropyLoss(ignore_index = 0)\noptim = torch.optim.Adam(trans.parameters(),lr=LR)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:23:19.436021Z","iopub.execute_input":"2022-08-07T15:23:19.436673Z","iopub.status.idle":"2022-08-07T15:23:20.009202Z","shell.execute_reply.started":"2022-08-07T15:23:19.436637Z","shell.execute_reply":"2022-08-07T15:23:20.007804Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"trans.num_of_parameters()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:23:20.011218Z","iopub.execute_input":"2022-08-07T15:23:20.011817Z","iopub.status.idle":"2022-08-07T15:23:20.036349Z","shell.execute_reply.started":"2022-08-07T15:23:20.011769Z","shell.execute_reply":"2022-08-07T15:23:20.035047Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    \n    \n    def __init__(self,model,loss_fn,optimizer,language_model,param_init,):\n        \n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.language_model = language_model\n        \n        if param_init:\n            self.init_param()\n        \n        \n        \n    def train(self,data,shuffle = True,n_iter = 1000,update_bar_per_iter = 100):\n        \n        self.model.train()\n        self.language_model.eval()\n        bar = tqdm(range(n_iter),desc = f\"Epoch -> {0} Loss -> {0.000} \")\n        \n        general_loss = 0.0\n        loss_per_update = 0.0\n        best_loss = 10e+9\n        batch_size = next(iter(dataloader))[0]['input_ids'].shape[0]\n        self.model2download = self.model.state_dict()\n        for i in bar:\n            \n                #index = random.randint(0,len(data))\n                src,trg = next(iter(dataloader))\n                \n                self.optimizer.zero_grad()\n\n                src_input_ids = src['input_ids'].squeeze(1)\n                src_att_mask = src['attention_mask'].squeeze(1)\n                trg_input_ids = trg['input_ids'].squeeze(1)\n\n                 #['input_ids']\n                with torch.no_grad():\n                    space_shift = self.language_model(input_ids=src_input_ids,\n                                                      attention_mask=src_att_mask)[0][:,0].unsqueeze(1)\n\n\n                \n                preds = self.model(src_input_ids=src_input_ids,src_att_mask=src_att_mask,\n                      trg_input_ids=trg_input_ids,space_shift=space_shift)\n                \n                \n                loss = self.loss_fn(preds.permute(1,2,0),trg_input_ids)\n                \n                general_loss += loss.item()\n                loss_per_update += loss.item()\n                loss.backward()\n                self.optimizer.step()\n                \n                \n                \n                \n                if not(i % update_bar_per_iter):\n                    bar.set_description(f\"Iteration-> {i+1} | Loss -> {general_loss /((i+1)*batch_size)}\")\n                    if loss_per_update < best_loss:\n                        best_loss = loss_per_update\n                        loss_per_update = 0.0\n                        self.model2download = self.model.state_dict()\n        \n    \n        \n    def init_param(self,):\n        \n        for x in self.model.parameters():\n            nn.init.normal_(x)\n            \n        \n        \n    def download_best_model(self,PATH):\n        torch.save(self.model2download, PATH)\n    \n    def load_pretrained_model(self,PATH):\n        self.model.load_state_dict(torch.load(PATH))\n             ","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:23:20.407655Z","iopub.execute_input":"2022-08-07T15:23:20.408026Z","iopub.status.idle":"2022-08-07T15:23:21.971413Z","shell.execute_reply.started":"2022-08-07T15:23:20.407994Z","shell.execute_reply":"2022-08-07T15:23:21.970215Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"data = Dataset(lines,tokenizer=tokenizer,max_seq_len=max_seq_len,device=device)\ndataloader = torch.utils.data.DataLoader(dataset=data,batch_size=8,shuffle=shuffle)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:23:21.973714Z","iopub.execute_input":"2022-08-07T15:23:21.974099Z","iopub.status.idle":"2022-08-07T15:23:21.983632Z","shell.execute_reply.started":"2022-08-07T15:23:21.974058Z","shell.execute_reply":"2022-08-07T15:23:21.982602Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(model=trans,loss_fn=loss_fn,optimizer=optim,language_model = language_model,param_init=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:23:21.986014Z","iopub.execute_input":"2022-08-07T15:23:21.986977Z","iopub.status.idle":"2022-08-07T15:23:21.995478Z","shell.execute_reply.started":"2022-08-07T15:23:21.986938Z","shell.execute_reply":"2022-08-07T15:23:21.994588Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"trainer.train(data=dataloader,n_iter=n_iter,update_bar_per_iter=update_bar_per_iter)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T15:23:22.234096Z","iopub.execute_input":"2022-08-07T15:23:22.235972Z","iopub.status.idle":"2022-08-07T20:16:59.518036Z","shell.execute_reply.started":"2022-08-07T15:23:22.235928Z","shell.execute_reply":"2022-08-07T20:16:59.516968Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"torch.save(trans.state_dict(), \"./model.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T20:24:25.789419Z","iopub.execute_input":"2022-08-07T20:24:25.789999Z","iopub.status.idle":"2022-08-07T20:24:26.523107Z","shell.execute_reply.started":"2022-08-07T20:24:25.789955Z","shell.execute_reply":"2022-08-07T20:24:26.522117Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}